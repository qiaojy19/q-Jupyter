{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class HMM(torch.nn.Module):\n",
    "  \"\"\"\n",
    "  Hidden Markov Model with discrete observations.\n",
    "  \"\"\"\n",
    "  def __init__(self, M, N):\n",
    "    super(HMM, self).__init__()\n",
    "    self.M = M # number of possible observations\n",
    "    self.N = N # number of states\n",
    "\n",
    "    # A\n",
    "    self.transition_model = TransitionModel(self.N)\n",
    "\n",
    "    # b(x_t)\n",
    "    self.emission_model = EmissionModel(self.N,self.M)\n",
    "\n",
    "    # pi\n",
    "    self.unnormalized_state_priors = torch.nn.Parameter(torch.randn(self.N))\n",
    "\n",
    "    # use the GPU\n",
    "    self.is_cuda = torch.cuda.is_available()\n",
    "    if self.is_cuda: self.cuda()\n",
    "\n",
    "class TransitionModel(torch.nn.Module):\n",
    "  def __init__(self, N):\n",
    "    super(TransitionModel, self).__init__()\n",
    "    self.N = N\n",
    "    self.unnormalized_transition_matrix = torch.nn.Parameter(torch.randn(N,N))\n",
    "\n",
    "class EmissionModel(torch.nn.Module):\n",
    "  def __init__(self, N, M):\n",
    "    super(EmissionModel, self).__init__()\n",
    "    self.N = N\n",
    "    self.M = M\n",
    "    self.unnormalized_emission_matrix = torch.nn.Parameter(torch.randn(N,M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sample(self, T=10):\n",
    "  state_priors = torch.nn.functional.softmax(self.unnormalized_state_priors, dim=0)\n",
    "  transition_matrix = torch.nn.functional.softmax(self.transition_model.unnormalized_transition_matrix, dim=0)\n",
    "  emission_matrix = torch.nn.functional.softmax(self.emission_model.unnormalized_emission_matrix, dim=1)\n",
    "\n",
    "  # sample initial state\n",
    "  z_t = torch.distributions.categorical.Categorical(state_priors).sample().item()\n",
    "  z = []; x = []\n",
    "  z.append(z_t)\n",
    "  for t in range(0,T):\n",
    "    # sample emission\n",
    "    x_t = torch.distributions.categorical.Categorical(emission_matrix[z_t]).sample().item()\n",
    "    x.append(x_t)\n",
    "\n",
    "    # sample transition\n",
    "    z_t = torch.distributions.categorical.Categorical(transition_matrix[:,z_t]).sample().item()\n",
    "    if t < T-1: z.append(z_t)\n",
    "\n",
    "  return x, z\n",
    "\n",
    "# Add the sampling method to our HMM class\n",
    "HMM.sample = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State priors: tensor([0.6225, 0.3775], device='cuda:0')\n",
      "Emission matrix: tensor([[0.0000, 0.0374, 0.0248, 0.0441, 0.0000, 0.0028, 0.0098, 0.0149, 0.0000,\n",
      "         0.0560, 0.0376, 0.1557, 0.1487, 0.0104, 0.0000, 0.0221, 0.0274, 0.0190,\n",
      "         0.0990, 0.0747, 0.0000, 0.0280, 0.1007, 0.0307, 0.0488, 0.0076],\n",
      "        [0.1298, 0.0000, 0.0000, 0.0000, 0.2359, 0.0000, 0.0000, 0.0000, 0.0779,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5135, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0429, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "Transition matrix: tensor([[0., 1.],\n",
      "        [1., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "alphabet = string.ascii_lowercase\n",
    "\n",
    "def encode(s):\n",
    "  \"\"\"\n",
    "  Convert a string into a list of integers\n",
    "  \"\"\"\n",
    "  x = [alphabet.index(ss) for ss in s]\n",
    "  return x\n",
    "\n",
    "def decode(x):\n",
    "  \"\"\"\n",
    "  Convert list of ints to string\n",
    "  \"\"\"\n",
    "  s = \"\".join([alphabet[xx] for xx in x])\n",
    "  return s\n",
    "\n",
    "# Initialize the model\n",
    "model = HMM(M=len(alphabet), N=2) \n",
    "\n",
    "# Hard-wiring the parameters!\n",
    "# Let state 0 = consonant, state 1 = vowel\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False # needed to do lines below\n",
    "model.unnormalized_state_priors[0] = 0.    # Let's start with a consonant more frequently\n",
    "model.unnormalized_state_priors[1] = -0.5\n",
    "print(\"State priors:\", torch.nn.functional.softmax(model.unnormalized_state_priors, dim=0))\n",
    "\n",
    "# In state 0, only allow consonants; in state 1, only allow vowels\n",
    "vowel_indices = torch.tensor([alphabet.index(letter) for letter in \"aeiou\"])\n",
    "consonant_indices = torch.tensor([alphabet.index(letter) for letter in \"bcdfghjklmnpqrstvwxyz\"])\n",
    "model.emission_model.unnormalized_emission_matrix[0, vowel_indices] = -np.inf\n",
    "model.emission_model.unnormalized_emission_matrix[1, consonant_indices] = -np.inf \n",
    "print(\"Emission matrix:\", torch.nn.functional.softmax(model.emission_model.unnormalized_emission_matrix, dim=1))\n",
    "\n",
    "# Only allow vowel -> consonant and consonant -> vowel\n",
    "model.transition_model.unnormalized_transition_matrix[0,0] = -np.inf  # consonant -> consonant\n",
    "model.transition_model.unnormalized_transition_matrix[0,1] = 0.       # vowel -> consonant\n",
    "model.transition_model.unnormalized_transition_matrix[1,0] = 0.       # consonant -> vowel\n",
    "model.transition_model.unnormalized_transition_matrix[1,1] = -np.inf  # vowel -> vowel\n",
    "print(\"Transition matrix:\", torch.nn.functional.softmax(model.transition_model.unnormalized_transition_matrix, dim=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  4,  8, 14, 20])\n",
      "tensor([ 1,  2,  3,  5,  6,  7,  9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22,\n",
      "        23, 24, 25])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(vowel_indices)\n",
    "print(consonant_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [16, 14, 18, 4, 10]\n",
      "decode x: qosek\n",
      "z: [0, 1, 0, 1, 0]\n",
      "x: [8, 18, 0, 16, 14]\n",
      "decode x: isaqo\n",
      "z: [1, 0, 1, 0, 1]\n",
      "x: [22, 14, 11, 4, 11]\n",
      "decode x: wolel\n",
      "z: [0, 1, 0, 1, 0]\n",
      "x: [12, 4, 11, 20, 23]\n",
      "decode x: melux\n",
      "z: [0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "  sampled_x, sampled_z = model.sample(T=5)\n",
    "  print(\"x:\", sampled_x)\n",
    "  print(\"decode x:\", decode(sampled_x))\n",
    "  print(\"z:\", sampled_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def HMM_forward(self, x, T):\n",
    "  \"\"\"\n",
    "  x : IntTensor of shape (batch size, T_max)\n",
    "  T : IntTensor of shape (batch size)\n",
    "\n",
    "  Compute log p(x) for each example in the batch.\n",
    "  T = length of each example\n",
    "  \"\"\"\n",
    "  if self.is_cuda:\n",
    "    x = x.cuda()\n",
    "    T = T.cuda()\n",
    "\n",
    "  batch_size = x.shape[0]; T_max = x.shape[1]\n",
    "  log_state_priors = torch.nn.functional.log_softmax(self.unnormalized_state_priors, dim=0)\n",
    "  log_alpha = torch.zeros(batch_size, T_max, self.N)\n",
    "  if self.is_cuda: log_alpha = log_alpha.cuda()\n",
    "\n",
    "  log_alpha[:, 0, :] = self.emission_model(x[:,0]) + log_state_priors\n",
    "  for t in range(1, T_max):\n",
    "    log_alpha[:, t, :] = self.emission_model(x[:,t]) + self.transition_model(log_alpha[:, t-1, :])\n",
    "\n",
    "  # Select the sum for the final timestep (each x may have different length).\n",
    "  log_sums = log_alpha.logsumexp(dim=2)\n",
    "  log_probs = torch.gather(log_sums, 1, T.view(-1,1) - 1)\n",
    "  return log_probs\n",
    "\n",
    "def emission_model_forward(self, x_t):\n",
    "  log_emission_matrix = torch.nn.functional.log_softmax(self.unnormalized_emission_matrix, dim=1)\n",
    "  out = log_emission_matrix[:, x_t].transpose(0,1)\n",
    "  return out\n",
    "\n",
    "def transition_model_forward(self, log_alpha):\n",
    "  \"\"\"\n",
    "  log_alpha : Tensor of shape (batch size, N)\n",
    "  Multiply previous timestep's alphas by transition matrix (in log domain)\n",
    "  \"\"\"\n",
    "  log_transition_matrix = torch.nn.functional.log_softmax(self.unnormalized_transition_matrix, dim=0)\n",
    "\n",
    "  # Matrix multiplication in the log domain\n",
    "  out = log_domain_matmul(log_transition_matrix, log_alpha.transpose(0,1)).transpose(0,1)\n",
    "  return out\n",
    "\n",
    "def log_domain_matmul(log_A, log_B):\n",
    "\t\"\"\"\n",
    "\tlog_A : m x n\n",
    "\tlog_B : n x p\n",
    "\toutput : m x p matrix\n",
    "\n",
    "\tNormally, a matrix multiplication\n",
    "\tcomputes out_{i,j} = sum_k A_{i,k} x B_{k,j}\n",
    "\n",
    "\tA log domain matrix multiplication\n",
    "\tcomputes out_{i,j} = logsumexp_k log_A_{i,k} + log_B_{k,j}\n",
    "\t\"\"\"\n",
    "\tm = log_A.shape[0]\n",
    "\tn = log_A.shape[1]\n",
    "\tp = log_B.shape[1]\n",
    "\n",
    "\t# log_A_expanded = torch.stack([log_A] * p, dim=2)\n",
    "\t# log_B_expanded = torch.stack([log_B] * m, dim=0)\n",
    "    # fix for PyTorch > 1.5 by egaznep on Github:\n",
    "\tlog_A_expanded = torch.reshape(log_A, (m,n,1))\n",
    "\tlog_B_expanded = torch.reshape(log_B, (1,n,p))\n",
    "\n",
    "\telementwise_sum = log_A_expanded + log_B_expanded\n",
    "\tout = torch.logsumexp(elementwise_sum, dim=1)\n",
    "\n",
    "\treturn out\n",
    "\n",
    "TransitionModel.forward = transition_model_forward\n",
    "EmissionModel.forward = emission_model_forward\n",
    "HMM.forward = HMM_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.8093]], device='cuda:0')\n",
      "tensor([[-8.3454],\n",
      "        [   -inf]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.stack( [torch.tensor(encode(\"cat\"))] )\n",
    "T = torch.tensor([3])\n",
    "print(model.forward(x, T))\n",
    "\n",
    "x = torch.stack( [torch.tensor(encode(\"aba\")), torch.tensor(encode(\"abb\"))] )\n",
    "T = torch.tensor([3,3])\n",
    "print(model.forward(x, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35033cad3aad510172903d36c0cbaff4bce9cf6615543ddd5b1706762055e814"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tian_g0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}